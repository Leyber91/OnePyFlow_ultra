# File: data_retrieval/pull_f2p_data.py

import logging
import pandas as pd
import os
from datetime import datetime

# Configure logging
logger = logging.getLogger(__name__)

def pull_f2p_data(session, fc, mp, cookie_jar):
    """
    Retrieves F2P data from the F2P_DICE.txt local file source.
    Reads the tab-separated file generated by an ETL job.

    Returns a DataFrame pivoted with 'Arc' as index and dates as columns,
    filtered for the specified FC.
    """
    try:
        # --- REVERTED FILE PATH BACK TO F2P_DICE.txt ---
        file_path = r'\\ant\dept-eu\BCN1\Public\ECFT\IXD\Weekly_ARC\F2P_DICE.txt'  # Reverted from F2P.txt
        logger.info(f"Attempting to read F2P data from: {file_path}")

        if not os.path.exists(file_path):
            logger.error(f"F2P data file not found at: {file_path}")
            return None

        # Add file size logging for better diagnostics
        try:
            file_size = os.path.getsize(file_path)
            logger.info(f"Found F2P file. Size: {file_size} bytes")
            if file_size == 0:
                logger.error(f"F2P data file is empty: {file_path}")
                return None
        except Exception as size_err:
            logger.error(f"Could not get file size for {file_path}: {size_err}")
            # Continue attempting to read, but log the error

        # Read the tab-separated file
        # Use error_bad_lines=False or on_bad_lines='skip' if file might have formatting issues
        raw_df = pd.read_csv(file_path, sep='\t', on_bad_lines='warn')
        logger.info(f"Successfully read F2P_DICE.txt with {len(raw_df)} initial rows")

        if raw_df.empty:
             logger.error("Pandas read 0 rows from F2P_DICE.txt. Check file content and separator.")
             return None

        # --- Filtering Logic (Seems okay, but added logging) ---
        filtered_df = pd.DataFrame() # Initialize empty DataFrame
        if fc:
            logger.info(f"Filtering F2P data for FC: {fc}")
            # Ensure 'arc' column exists before filtering
            if 'arc' not in raw_df.columns:
                logger.error(f"'arc' column not found in F2P_DICE.txt. Columns are: {raw_df.columns.tolist()}")
                return None

            # Approach 1: arc starts with FC_
            fc_prefix_filter = raw_df['arc'].str.startswith(f"{fc}_", na=False)

            # Approach 2: arc exactly matches FC (less common for F2P arcs)
            fc_exact_filter = raw_df['arc'] == fc

            # Combine filters
            combined_filter = fc_prefix_filter | fc_exact_filter
            filtered_df = raw_df[combined_filter]

            if not filtered_df.empty:
                logger.info(f"Filtered to {len(filtered_df)} rows for FC {fc} using prefix/exact match.")
            else:
                # Fallback: Try matching based on the first part of the arc
                logger.info(f"No direct prefix/exact match for {fc}. Trying partial match on arc start.")
                # Extract potential FC codes (part before first '_')
                # Handle potential errors if split doesn't work
                try:
                    potential_fcs = raw_df['arc'].str.split('_', n=1).str[0].unique()
                    logger.debug(f"Potential FC codes found in 'arc' column: {potential_fcs}")
                    # Case-insensitive match
                    fc_lower = fc.lower()
                    matched_fc = next((code for code in potential_fcs if isinstance(code, str) and code.lower() == fc_lower), None)

                    if matched_fc:
                        logger.info(f"Found partial match for '{fc}' as '{matched_fc}'. Filtering based on '{matched_fc}_'.")
                        filtered_df = raw_df[raw_df['arc'].str.startswith(f"{matched_fc}_", na=False)]
                        logger.info(f"Filtered to {len(filtered_df)} rows using partial match.")
                    else:
                        logger.warning(f"No matching data found for FC: {fc} after all filtering attempts.")
                except Exception as split_err:
                    logger.error(f"Error during fallback FC matching: {split_err}", exc_info=True)
                    # filtered_df remains empty

        else:
             # If no FC provided, use the whole dataset (might be large)
             logger.warning("No FC provided for filtering F2P data. Using all data.")
             filtered_df = raw_df # Use the original DataFrame


        # Check if filtering resulted in an empty DataFrame
        if filtered_df.empty:
            logger.warning(f"No F2P data available after filtering for FC '{fc}'.")
            return None

        # --- REVERTED date column name ---
        date_column_name = 'day'  # Reverted from 'forecast_date'
        value_column_name = 'f2p'
        index_column_name = 'arc'

        # Verify required columns exist before proceeding
        required_cols = [date_column_name, value_column_name, index_column_name]
        if not all(col in filtered_df.columns for col in required_cols):
             logger.error(f"Missing one or more required columns ({required_cols}) in F2P data. Found: {filtered_df.columns.tolist()}")
             return None

        # Convert date column to proper date format ('YYYY-MM-DD')
        try:
            # Use errors='coerce' to turn unparseable dates into NaT (Not a Time)
            filtered_df[date_column_name] = pd.to_datetime(filtered_df[date_column_name], errors='coerce').dt.strftime('%Y-%m-%d')
            # Drop rows where date conversion failed
            original_rows = len(filtered_df)
            filtered_df.dropna(subset=[date_column_name], inplace=True)
            if len(filtered_df) < original_rows:
                logger.warning(f"Dropped {original_rows - len(filtered_df)} rows due to invalid date format in '{date_column_name}' column.")
            if filtered_df.empty:
                logger.error(f"No valid date entries found in '{date_column_name}' column after conversion.")
                return None
        except Exception as date_err:
             logger.error(f"Error converting '{date_column_name}' column to datetime: {date_err}", exc_info=True)
             return None


        # Create a pivot table
        logger.debug(f"Creating pivot table with index='{index_column_name}', columns='{date_column_name}', values='{value_column_name}'")
        try:
            pivot_df = filtered_df.pivot_table(
                index=index_column_name,
                columns=date_column_name, # Use correct date column name
                values=value_column_name,
                aggfunc='first' # Use first value if duplicate arc/date pairs exist
            ).reset_index()
        except Exception as pivot_err:
             logger.error(f"Error creating pivot table: {pivot_err}", exc_info=True)
             return None

        # Clean up column names
        pivot_df.columns.name = None

        # Rename the first column to 'Arc'
        column_mapping = {pivot_df.columns[0]: 'Arc'}
        pivot_df.rename(columns=column_mapping, inplace=True)

        # Replace any NaN values with 0
        pivot_df.fillna(0, inplace=True)

        # Sort by the latest date column's values (descending)
        if len(pivot_df.columns) > 1:
            # Date columns are now strings 'YYYY-MM-DD', sort them lexicographically
            date_columns = sorted([col for col in pivot_df.columns if col != 'Arc'])
            if date_columns:
                latest_date = date_columns[-1] # Get the latest date string
                logger.info(f"Sorting data by latest date column: {latest_date}")
                pivot_df = pivot_df.sort_values(by=latest_date, ascending=False)
            else:
                logger.warning("No date columns found in pivot table for sorting.")
        else:
             logger.warning("Pivot table only contains 'Arc' column, skipping sort.")


        logger.info(f"F2P data processing complete. Result has {len(pivot_df)} arcs and {len(pivot_df.columns)-1} days.")
        return pivot_df

    except FileNotFoundError:
        logger.error(f"F2P data file not found at the specified path: {file_path}")
        return None
    except pd.errors.EmptyDataError:
         logger.error(f"F2P data file is empty or contains no columns: {file_path}")
         return None
    except Exception as e:
        logger.error(f"General error retrieving/processing F2P data from local file: {e}", exc_info=True)
        return None